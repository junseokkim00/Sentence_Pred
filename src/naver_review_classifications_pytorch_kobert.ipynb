{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6rbUsQ6RTW6"
      },
      "source": [
        "# KoBERT finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## prepare libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz-3kcFJRTW8",
        "outputId": "b472760c-1a55-4c9a-bbd3-562141493a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets\n",
            "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/b8/d4/ce436660098b2f456e2b8fdf76d4f33cbc3766c874c4aa2f772c7a5e943f/ipywidgets-8.1.0-py3-none-any.whl.metadata\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting comm>=0.1.3 (from ipywidgets)\n",
            "  Obtaining dependency information for comm>=0.1.3 from https://files.pythonhosted.org/packages/fe/47/0133ac1b7dc476ed77710715e98077119b3d9bae56b13f6f9055e7da1c53/comm-0.1.4-py3-none-any.whl.metadata\n",
            "  Downloading comm-0.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipywidgets) (8.12.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.7 (from ipywidgets)\n",
            "  Obtaining dependency information for widgetsnbextension~=4.0.7 from https://files.pythonhosted.org/packages/8e/d4/d31b12ac0b87e8cc9fdb6ea1eb6596de405eaaa2f25606aaa755d0eebbc0/widgetsnbextension-4.0.8-py3-none-any.whl.metadata\n",
            "  Downloading widgetsnbextension-4.0.8-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab-widgets~=3.0.7 (from ipywidgets)\n",
            "  Obtaining dependency information for jupyterlab-widgets~=3.0.7 from https://files.pythonhosted.org/packages/74/5e/2475ac62faf2e342b2bf20b8d8e375f49400ecb38f52e4e0a7557eb1cedb/jupyterlab_widgets-3.0.8-py3-none-any.whl.metadata\n",
            "  Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: backcall in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: decorator in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: appnope in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: executing in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Downloading ipywidgets-8.1.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
            "Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, comm, ipywidgets\n",
            "  Attempting uninstall: comm\n",
            "    Found existing installation: comm 0.1.2\n",
            "    Uninstalling comm-0.1.2:\n",
            "      Successfully uninstalled comm-0.1.2\n",
            "Successfully installed comm-0.1.4 ipywidgets-8.1.0 jupyterlab-widgets-3.0.8 widgetsnbextension-4.0.8\n",
            "Collecting mxnet\n",
            "  Using cached mxnet-1.6.0-py2.py3-none-any.whl (68.7 MB)\n",
            "Collecting numpy<2.0.0,>1.16.0 (from mxnet)\n",
            "  Obtaining dependency information for numpy<2.0.0,>1.16.0 from https://files.pythonhosted.org/packages/86/a1/b8ef999c32f26a97b5f714887e21f96c12ae99a38583a0a96e65283ac0a1/numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
            "Collecting requests<3,>=2.20.0 (from mxnet)\n",
            "  Obtaining dependency information for requests<3,>=2.20.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.20.0->mxnet)\n",
            "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/91/e6/8fa919fc84a106e9b04109de62bdf8526899e2754a64da66e1cd50ac1faa/charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.20.0->mxnet)\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.20.0->mxnet)\n",
            "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
            "  Downloading urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.20.0->mxnet)\n",
            "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, numpy, idna, graphviz, charset-normalizer, certifi, requests, mxnet\n",
            "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 graphviz-0.8.4 idna-3.4 mxnet-1.6.0 numpy-1.25.2 requests-2.31.0 urllib3-2.0.4\n",
            "Collecting gluonnlp==0.8.0\n",
            "  Using cached gluonnlp-0.8.0.tar.gz (235 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from gluonnlp==0.8.0) (1.25.2)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.8.0-py3-none-any.whl size=292701 sha256=aa107aef6527293941f3322d25662d026f253b2e082ca68e7e6530f456094e0b\n",
            "  Stored in directory: /Users/andrew/Library/Caches/pip/wheels/d4/33/10/735728ff9ab4891a97789d842c70354bdb368715e35f18fb9e\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.8.0\n",
            "Collecting tqdm\n",
            "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/e5/cd/c941b51e95992968e3e8abc7180f33b952478abd6943062051517a808db7/pandas-2.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading pandas-2.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
            "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.0-cp311-cp311-macosx_11_0_arm64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, tzdata, tqdm, pandas\n",
            "Successfully installed pandas-2.1.0 pytz-2023.3.post1 tqdm-4.66.1 tzdata-2023.3\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Collecting transformers\n",
            "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/13/30/54b59e73400df3de506ad8630284e9fd63f4b94f735423d55fc342181037/transformers-4.33.1-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from transformers)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/52/90/45223db4e1df30ff14e8aebf9a1bf0222da2e7b49e53692c968f36817812/filelock-3.12.3-py3-none-any.whl.metadata\n",
            "  Downloading filelock-3.12.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from transformers) (23.1)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/28/09/55f715ddbf95a054b764b547f617e22f1d5e45d83905660e9a088078fe67/PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/03/5e/9a4cabe86a3b4e67bd2cf795a2e84de01c735c8c1c1d88795425847ccbbe/regex-2023.8.8-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading regex-2023.8.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-macosx_12_0_arm64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/34/0e/12d55d5dd648b8f7ea7216c5b7cef9703b4dbd3b2a042872c711d5e98551/safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl.metadata\n",
            "  Downloading safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
            "Collecting fsspec (from huggingface-hub<1.0,>=0.15.1->transformers)\n",
            "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/3a/9f/b40e8e5be886143379000af5fc0c675352d59e82fd869d24bf784161dc77/fsspec-2023.9.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2023.9.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.15.1->transformers)\n",
            "  Obtaining dependency information for typing-extensions>=3.7.4.3 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
            "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
            "Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.8.8-cp311-cp311-macosx_11_0_arm64.whl (289 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl (406 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.9/406.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.12.3-py3-none-any.whl (11 kB)\n",
            "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, safetensors, typing-extensions, regex, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
            "Successfully installed filelock-3.12.3 fsspec-2023.9.0 huggingface-hub-0.16.4 pyyaml-6.0.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1 typing-extensions-4.7.1\n",
            "Collecting torch\n",
            "  Downloading torch-2.0.1-cp311-none-macosx_11_0_arm64.whl (55.8 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0mm\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages (from torch) (4.7.1)\n",
            "Collecting sympy (from torch)\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/fe/09/c31503cb8150cf688c1534a7135cc39bb9092f8e0e6369ec73494d16ee0e/MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl (17 kB)\n",
            "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
            "Successfully installed MarkupSafe-2.1.3 jinja2-3.1.2 mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /private/var/folders/0r/6ncbx7693d96pr3xr0xpgt8w0000gn/T/pip-install-90_d97bx/kobert-tokenizer_61ca6f69bb3b478a8284029e18fddd52\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /private/var/folders/0r/6ncbx7693d96pr3xr0xpgt8w0000gn/T/pip-install-90_d97bx/kobert-tokenizer_61ca6f69bb3b478a8284029e18fddd52\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: kobert_tokenizer\n",
            "  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=bbfb05330952ab88882bb1e30b86f8e9a88c4af5bd8cb9f341f34a1e918ac73d\n",
            "  Stored in directory: /private/var/folders/0r/6ncbx7693d96pr3xr0xpgt8w0000gn/T/pip-ephem-wheel-cache-d5xowk5v/wheels/b7/95/7c/3f38b039ae9422cc4a51702b37e352d0585442cbe60285f1f2\n",
            "Successfully built kobert_tokenizer\n",
            "Installing collected packages: kobert_tokenizer\n",
            "Successfully installed kobert_tokenizer-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets  # for vscode\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp==0.8.0\n",
        "!pip install tqdm pandas\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gAWGdas9RTW8"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "dlopen(/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so, 0x0006): tried: '/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (no such file), '/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgluonnlp\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnlp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/gluonnlp/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding: utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"NLP toolkit.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m loss\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m embedding\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/gluonnlp/loss/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# coding: utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"NLP loss.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mactivation_regularizer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloss\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlabel_smoothing\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/gluonnlp/loss/activation_regularizer.py:25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"Language model RNN loss.\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mActivationRegularizationLoss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTemporalActivationRegularizationLoss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmxnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgluon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloss\u001b[39;00m \u001b[39mimport\u001b[39;00m Loss\n\u001b[1;32m     28\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mActivationRegularizationLoss\u001b[39;00m(Loss):\n\u001b[1;32m     29\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes Activation Regularization Loss. (alias: AR)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[39m    The formulation is as below:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m        The axis that represents mini-batch.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/__init__.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m\"\"\"MXNet: a concise, fast and flexible framework for deep learning.\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m Context, current_context, cpu, gpu, cpu_pinned\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m engine\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m MXNetError\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/context.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mctypes\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m classproperty, with_metaclass, _MXClassPropertyMetaClass\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m _LIB\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m check_call\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/base.py:214\u001b[0m\n\u001b[1;32m    212\u001b[0m __version__ \u001b[39m=\u001b[39m libinfo\u001b[39m.\u001b[39m__version__\n\u001b[1;32m    213\u001b[0m \u001b[39m# library instance of mxnet\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m _LIB \u001b[39m=\u001b[39m _load_lib()\n\u001b[1;32m    216\u001b[0m \u001b[39m# type definitions\u001b[39;00m\n\u001b[1;32m    217\u001b[0m mx_int \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/base.py:205\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load library by searching possible path.\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m lib_path \u001b[39m=\u001b[39m libinfo\u001b[39m.\u001b[39mfind_lib_path()\n\u001b[0;32m--> 205\u001b[0m lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCDLL(lib_path[\u001b[39m0\u001b[39m], ctypes\u001b[39m.\u001b[39mRTLD_LOCAL)\n\u001b[1;32m    206\u001b[0m \u001b[39m# DMatrix functions\u001b[39;00m\n\u001b[1;32m    207\u001b[0m lib\u001b[39m.\u001b[39mMXGetLastError\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/proj/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, mode)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so, 0x0006): tried: '/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (no such file), '/Users/andrew/opt/anaconda3/envs/proj/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BmNVo3e2RTW9"
      },
      "outputs": [],
      "source": [
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cSYM5rxPRTW9"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZtjEu1ocRTW9"
      },
      "outputs": [],
      "source": [
        "## CPU\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "## GPU\n",
        "# device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt57nECWRTW9",
        "outputId": "dbad7a66-71b0-403e-97a4-d4a045b08848"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "# bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyEv-v64RTW-",
        "outputId": "6ed3a6c2-d18a-4c47-e483-9da36b3164ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-07 11:41:11--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
            "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.204.27, 52.219.144.55, 52.219.202.51, ...\n",
            "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.204.27|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  7.25MB/s    in 1.9s    \n",
            "\n",
            "2023-09-07 11:41:14 (7.25 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n",
            "--2023-09-07 11:41:14--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt\n",
            "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.204.27, 52.219.144.55, 52.219.202.51, ...\n",
            "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.204.27|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [text/plain]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  3.34MB/s    in 1.4s    \n",
            "\n",
            "2023-09-07 11:41:16 (3.34 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
        "!wget -O ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LsUAXaj8RTW-"
      },
      "outputs": [],
      "source": [
        "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kNtStmea-gc",
        "outputId": "30ebe8d6-8763-4fd1-e747-9bf5f6fe35da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['아 더빙.. 진짜 짜증나네요 목소리', '0'],\n",
              " ['흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'],\n",
              " ['너무재밓었다그래서보는것을추천한다', '0'],\n",
              " ['교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'],\n",
              " ['사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'],\n",
              " ['막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'],\n",
              " ['원작의 긴장감을 제대로 살려내지못했다.', '0'],\n",
              " ['별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네',\n",
              "  '0'],\n",
              " ['액션이 없는데도 재미 있는 몇안되는 영화', '1'],\n",
              " ['왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1'],\n",
              " ['걍인피니트가짱이다.진짜짱이다♥', '1'],\n",
              " ['볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~', '1'],\n",
              " ['울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해', '0'],\n",
              " ['담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.', '1'],\n",
              " ['취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지', '0'],\n",
              " ['ㄱ냥 매번 긴장되고 재밋음ㅠㅠ', '1'],\n",
              " ['참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다', '1'],\n",
              " ['굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐', '0'],\n",
              " ['이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥', '1'],\n",
              " ['약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.', '1'],\n",
              " ['나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님', '1'],\n",
              " ['보면서 웃지 않는 건 불가능하다', '1'],\n",
              " ['재미없다 지루하고. 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남....바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 ; 이건 볼게없다 음식도 별로 안나오고, 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ㅡㅡ',\n",
              "  '0'],\n",
              " ['절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다.', '1'],\n",
              " ['주제는 좋은데 중반부터 지루하다', '0'],\n",
              " ['다 짤랐을꺼야. 그래서 납득할 수 없었던거야.. 그럴꺼야.. 꼭 그랬던걸꺼야..', '0'],\n",
              " ['kl2g 고추를 털어버려야 할텐데', '1'],\n",
              " ['카밀라벨 발연기', '0'],\n",
              " ['재밋는뎅', '1'],\n",
              " ['센스있는 연출력..탁월한 캐스팅..90년대의 향수.. 그래서 9점..', '1']]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0utOnohlRTW-"
      },
      "outputs": [],
      "source": [
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "lDII_phFRTW-"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        # self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.sentences = [i for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7R-TarKfRTW-"
      },
      "outputs": [],
      "source": [
        "## Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "nssWbJFuRTW-"
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F_TXkH1RTW-",
        "outputId": "041e79af-a649-4d14-ea8b-ed986839a914"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "u0lp0lR7RTW_"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=2,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        else:\n",
        "            out = pooler\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aN3OTIQrRTW_"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "At-TPv4pRTW_"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr1nphUiRTW_",
        "outputId": "77d01462-c698-4c0b-de8d-c22f852606e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Jrm9qUmMRTW_"
      },
      "outputs": [],
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0465lE6hRTW_"
      },
      "outputs": [],
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "65uJ0fcjRTW_"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "019dbc7f540d411a814f038d2b64118f",
            "f1dac9a408f1412b9752af87109a81a3",
            "d38a50ada03142ecbb7533f77c1726a6",
            "b854f57edecf44f6ac40c4aff0ee807d",
            "c6b0ff0f125a4e708c64f672189ad1d7",
            "60b44b41c4fc46eba19f7ef18bb3effa",
            "97daf83a12f440be9be7c19bc2f0cb3c",
            "233160ed65c14c79a34e4d596e1b72a6",
            "3bafb06249be4b60bf8a6393d8145765",
            "5a38637b96e5439586d649f85a44df90",
            "d909566a6b7a4a3da6f7e8a216cf2d89"
          ]
        },
        "id": "-R6lLoJcRTW_",
        "outputId": "f164ed6d-7e66-49bb-d58b-3704a1c4739c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "019dbc7f540d411a814f038d2b64118f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2344 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-74720bcb0ea6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-52-311973be92a8>\", line 12, in __getitem__\n    return (self.sentences[i] + (self.labels[i], ))\nTypeError: can only concatenate list (not \"tuple\") to list\n"
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh4T-YCbcxPT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "019dbc7f540d411a814f038d2b64118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1dac9a408f1412b9752af87109a81a3",
              "IPY_MODEL_d38a50ada03142ecbb7533f77c1726a6",
              "IPY_MODEL_b854f57edecf44f6ac40c4aff0ee807d"
            ],
            "layout": "IPY_MODEL_c6b0ff0f125a4e708c64f672189ad1d7"
          }
        },
        "233160ed65c14c79a34e4d596e1b72a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bafb06249be4b60bf8a6393d8145765": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a38637b96e5439586d649f85a44df90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b44b41c4fc46eba19f7ef18bb3effa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97daf83a12f440be9be7c19bc2f0cb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b854f57edecf44f6ac40c4aff0ee807d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a38637b96e5439586d649f85a44df90",
            "placeholder": "​",
            "style": "IPY_MODEL_d909566a6b7a4a3da6f7e8a216cf2d89",
            "value": " 0/2344 [00:00&lt;?, ?it/s]"
          }
        },
        "c6b0ff0f125a4e708c64f672189ad1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38a50ada03142ecbb7533f77c1726a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233160ed65c14c79a34e4d596e1b72a6",
            "max": 2344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bafb06249be4b60bf8a6393d8145765",
            "value": 0
          }
        },
        "d909566a6b7a4a3da6f7e8a216cf2d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1dac9a408f1412b9752af87109a81a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b44b41c4fc46eba19f7ef18bb3effa",
            "placeholder": "​",
            "style": "IPY_MODEL_97daf83a12f440be9be7c19bc2f0cb3c",
            "value": "  0%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
