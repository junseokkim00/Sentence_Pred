{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRELIMINARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install torch\n",
    "%pip install git+https://github.com/huggingface/transformers.git\n",
    "%pip install tqdm\n",
    "%pip install git+https://github.com/huggingface/accelerate.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/junseokkim00/anaconda3/envs/cite3/lib/python3.11/site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESTART KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    PreTrainedTokenizerFast,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data):\n",
    "        self.data = data\n",
    "        self.length = self.data.shape[0]\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        prev, _next = self.data.iloc[i]['prev'], self.data.iloc[i]['next']\n",
    "        prev = self.tokenizer.encode(prev)\n",
    "        _next = self.tokenizer.encode(_next)\n",
    "        # inputs_id = prev + [self.tokenizer.bos_token_id] + _next\n",
    "        inputs_id = prev + _next\n",
    "        while len(inputs_id) < 50:\n",
    "            inputs_id.append(self.tokenizer.pad_token_id)\n",
    "        \n",
    "        outputs_id = [self.tokenizer.mask_token_id,] * (len(prev)-1) + _next + [self.tokenizer.eos_token_id]\n",
    "        while len(outputs_id) < 50:\n",
    "            outputs_id.append(self.tokenizer.pad_token_id)\n",
    "        mask = [0] * len(prev) + [1] * len(_next) + [0] * (50 - len(prev) - len(_next))\n",
    "        inputs_id = torch.LongTensor(inputs_id).to(device)\n",
    "        outputs_id = torch.LongTensor(outputs_id).to(device)\n",
    "        mask = torch.LongTensor(mask).to(device)\n",
    "        return inputs_id, mask, outputs_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPTDataLoader(tokenizer, data, batch_size):\n",
    "    data = GPTDataset(tokenizer=tokenizer, data=data)\n",
    "    return DataLoader(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "data_dir = \"./data\"\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 2e-5\n",
    "warmup_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name, bos_token='<s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
    "file_path = os.path.join(data_dir, \"final_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train and val dataloader\n",
    "data = pd.read_csv(file_path)[['prev', 'next']]\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "num = int(len(data) * 0.8)\n",
    "train_data, val_data = data[:num], data[:num]\n",
    "\n",
    "train_dataloader = GPTDataLoader(tokenizer=tokenizer,data=train_data, batch_size=batch_size)\n",
    "val_dataloader = GPTDataLoader(tokenizer=tokenizer, data=val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to train mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "min_loss = int(1e9)\n",
    "Sneg = -1e18\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Training epoch {epoch}\")\n",
    "    for samples in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, mask, label = samples\n",
    "        out = model(input_ids)\n",
    "        out = out.logits\n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "        loss = criterion(mask_out.transpose(2, 1), label)\n",
    "        avg_loss = loss.sum() / mask.sum()\n",
    "        # out = model(input_ids, labels=label)\n",
    "        # loss = out[0]\n",
    "        avg_loss.backward()\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    cnt=0\n",
    "    with torch.no_grad():\n",
    "        test_loss=0\n",
    "        for samples in tqdm(val_dataloader):\n",
    "            cnt+=1\n",
    "            input_ids, mask, label = samples\n",
    "            out = model(input_ids)\n",
    "            out = out.logits\n",
    "            mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "            mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
    "            loss = criterion(mask_out.transpose(2, 1), label)\n",
    "            avg_loss = loss.sum() / mask.sum()\n",
    "            # out = model(input_ids, labels=label)\n",
    "            # loss = out[0]\n",
    "            test_loss+=avg_loss\n",
    "            # test_loss+=loss\n",
    "        test_loss/=cnt\n",
    "        print(f\"epoch: {epoch}/{epochs} valdiation loss: {test_loss:0.2f}\")\n",
    "\n",
    "        if test_loss < min_loss:\n",
    "            min_loss = test_loss\n",
    "            model.save_pretrained(\"./best_model_theRealNewVersion\")\n",
    "print(\"Training Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cite3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
